<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="A. Onofri, H-P. Piepho and Marcin Kozak" />


<title>Example 3 continued. Fitting a mixed effect survival model</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = false;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">agriCensData</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Example1.html">Example 1</a>
</li>
<li>
  <a href="Example2.html">Example 2</a>
</li>
<li>
  <a href="Example3.html">Example 3</a>
</li>
<li>
  <a href="RandomEffects.html">Random effects</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Example 3 continued. Fitting a mixed effect survival model</h1>
<h4 class="author"><em>A. Onofri, H-P. Piepho and Marcin Kozak</em></h4>

</div>


<hr />
<div id="the-model-definition-in-jags-code" class="section level1">
<h1>The model definition (in JAGS code)</h1>
<p>In the previous session (<a href="https://onofriandreapg.github.io/agriCensData/Example3.html">here</a>) we have fitted a survival model to a dataset relating to potato starch grains assessed in size categories. Our analyses assumed that starch grains were independent, an artificial assumption - because they actually were <em>not</em> independent, being grouped by photo. Starch grains observed in the same photo can be correlated and thus similar to each other. In our paper, we discuss that neglecting this correlation we incorrectly treated the 2,441 starch grains as 2,441 independent pieces of information, leading to overly small standard errors of our estimates.</p>
<p>Including random effects in a survival model is difficult, unless we use Bayesian methods. In our paper, we already discussed the differences between traditional and Bayesian statistics; therefore, we will not make this point again here, but instead we will concentrate on the fitting process. The model we are going to fit is as follows:</p>
<p><span class="math display">\[ y_{ijk} = \mu_j+ \gamma_k + \varepsilon_{ijk} \]</span></p>
<p>where <span class="math inline">\(y_{ijk}\)</span> is the diameter of the <span class="math inline">\(i\)</span>-th grain in the <span class="math inline">\(k\)</span>-th phot for the <span class="math inline">\(j\)</span>-th producer, <span class="math inline">\(\mu_j\)</span> is the mean diameter for the <span class="math inline">\(j\)</span>-th producer, <span class="math inline">\(\gamma_k\)</span> is the random error for the <span class="math inline">\(k\)</span>-th photo, and <span class="math inline">\(\varepsilon_{ijk}\)</span> is the residual error term. We will assume that <span class="math inline">\(\varepsilon\)</span> is homoscedastic and normally distributed, with mean equal to zero and standard deviation equal to <span class="math inline">\(\sigma\)</span>. We will also assume that <span class="math inline">\(\gamma\)</span> (the random photo effect) is normally distributed, independent of <span class="math inline">\(\epsilon\)</span>, with mean equal to 0 and standard deviation equal to <span class="math inline">\(\sigma_p\)</span>. This standard deviation represents the photo-to-photo variability, while the residual standard deviation represents the within-group (within-photo) variability.</p>
<p>To fit the above model, we used the MCMC sampler provided with the freeware software JAGS (Just Another Gibbs Sampler), which can be invoked from an R session with the <code>rjags</code> package <span class="citation">(Plummer 2016)</span>.</p>
<p>First, we need to specify a model (in JAGS code) in a text string (<code>modelSpec</code>), like below.</p>
<pre class="r"><code># Save BUGS description of the model as a string
modelSpec &lt;- &quot;
data{
for (i in 1:N) {
  zeros[i] &lt;- 0
}}

model{
for (i in 1:N) {
  exp[i] &lt;- mu[Group[i]] + gamma[Photo[i]]
}

for (i in 1:N1) {
  #Likelihood for left-censored
  S2[i] &lt;- pnorm(high[i], exp[i], tau.e)
  L[i] &lt;- S2[i]     #(Equation 3)       
  phi[i] &lt;- -(log(L[i]))
  zeros[i] ~ dpois(phi[i])    
}

for (i in (N1+1):N2) {
  #Likelihood for interval-censored
  S[i] &lt;- pnorm(low[i], exp[i], tau.e)
  S2[i] &lt;- pnorm(high[i], exp[i], tau.e)
  L[i] &lt;- S2[i] - S[i]  #(Equation 4)      
  phi[i] &lt;- -(log(L[i]))
  zeros[i] ~ dpois(phi[i])    
}

for (i in (N2+1):N) {
  #Likelihood for right-censored
  S[i] &lt;- pnorm(low[i], exp[i], tau.e)
  L[i] &lt;- 1 - S[i]  #(Equation 5)      
  phi[i] &lt;- -(log(L[i]))
  zeros[i] ~ dpois(phi[i])    
}

#Priors
  sigma.e ~ dunif(0, 100)
  sigma.P ~ dunif(0, 100)
for(i in 1:2){
  mu[i] ~ dnorm(0, 0.000001)
} for(i in 1:24){
   gamma[i] ~ dnorm(0, tau.P)
}

#Derived quantities
  sigma2p &lt;- sigma.P*sigma.P
  sigma2e &lt;- sigma.e*sigma.e
  tau.P &lt;- 1 / sigma2p
  tau.e &lt;- 1 / sigma2e
  diff &lt;- mu[1] - mu[2]
}
&quot;</code></pre>
<p>This definition contains an (initial) data step, where we create a new variable (<code>zeros[i]</code>) by assigning a value of 0 to all observations. We will clarify why this data step is necessary.</p>
<p>Then, a model step follows, where we code the model we want to fit. This returns the expected value for each observation (<code>exp[i]</code>). Note the coding with double square brackets (<code>mu[Group[i]]</code>), which is used to mean that <code>mu</code> takes different values, depending on <code>Group[i]</code>.</p>
<p>The next part codes the log-likelihood for the <span class="math inline">\(i\)</span>-th observation. The observations are assumed to be sorted, so that right-censored observations take the positions from 1 to N1, interval-censored observations take the positions from N1 to N2, and left-censored observations take the postions from N2 to the end of the dataset. For each group, the negative log-likelihood is coded according to the Equations from 3 to 5 in our paper and is stored in the variable <code>phi</code>.</p>
<p>At this stage, we need to make JAGS use <code>phi</code> to calculate the likelihood for each observation. Such calculation might seem easy, since the likelihood is equal to <code>exp(-phi)</code>. Unfortunately, JAGS/BUGS can only calculate the likelihood using a few pre-defined functions, none of which providing a simple direct solution.</p>
<p>This problem can be solved by using the so-called ‘zeros trick’ <span class="citation">(Spiegelhalter et al. 2003)</span>: the trick is to set the observed value for the <span class="math inline">\(i\)</span>-th observation as <code>zeros[i] = 0</code>, which we have done in the first (data) step. We now need to specify that the observed value (0 for all observations) is distributed according to a Poisson probability function (i.e., one of the available pre-defined functions) with mean equal to phi; we can do this with the command <code>zeros[i] ~ dpois(phi[i])</code>. Note that the probability of obtaining zero from a Poisson distribution with mean equal to phi is exactly <span class="math inline">\(e^{-phi}\)</span>. sO, with this “zeros trick” the software can assign the correct likelihood to each individual observation.</p>
<p>Finally, we have to define the priors for all the parameters. For both variance parameters, we selected a uniform distribution from 0 to 100 (<code>sigma.e ~ dunif(0, 100)</code>). For <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\mu_2\)</span> our prior expectation was that they were normally distributed with a mean of 0 and a very high standard deviation (<span class="math inline">\(\sigma\)</span> = 103). So high an SD value used as a prior information means that, without looking at the experimental data, we had no idea about the values of these unknown parameters. The priors for <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\mu_2\)</span> were set with the command <code>mu[i] ~ dnorm(0, 0.000001)</code>, which specifies the normal distribution using the mean of 0 and the precision of 0.000001, the precision being <span class="math inline">\(1/\sigma^2\)</span>. Such a parameterisation is used by JAGS and other MCMC samplers, such as WinBUGS.</p>
<p>In the above model definition, we also added some derived quantities, to be calculated from the estimated parameters, such as the difference between <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\mu_2\)</span>.</p>
<hr />
</div>
<div id="model-fitting-in-r" class="section level1">
<h1>Model fitting in R</h1>
<p>So, we coded the model and assigned it to a text string (<code>modelSpec</code>). Before we start fitting the model, however, we have to</p>
<ol style="list-style-type: decimal">
<li>Store the model definition in an external text file (‘censoredMixedModel.txt’), using the function <code>writeLines()</code>.</li>
<li>Load the dataset. We will reuse the dataset in the ungrouped form, which we used to fit the survival model. Let’s recall that this data set is available in the package <code>agriCensData</code> as <code>starchGrainU</code>.</li>
<li>Sort the dataset in an ascending class order, so that the individuals in the first diameter class (left-censored) begin the data set (from row 1 to row 639) and the individuals in the 5th diameter class (right-censored) end it (from row 2,131 to row 2,441).</li>
<li>Define a few variables that are used in the model definition, such as <code>N</code> (the number of observations), <code>N1</code> (the number of left-censored observations, i.e., 639), and <code>N2</code> (the number of left-censored plus interval-censored observations, i.e., 2130).</li>
</ol>
<pre class="r"><code>library(agriCensData)
writeLines(modelSpec, con = &quot;censoredMixedModel.txt&quot;)
data(starchGrainU)
dataset_jags &lt;- starchGrainU[order(starchGrainU$Class), ]
N1 &lt;- 639
N2 &lt;- 2130
N &lt;- 2441</code></pre>
<p>Now we are ready to fit the model. To this aim, we will</p>
<ol style="list-style-type: decimal">
<li>load the <code>rjags</code> library;</li>
<li>create two lists: a list of all the data needed for the analysis (<code>win.data</code>) and a list of the initial values for the parameters to be estimated (<code>init</code>); and</li>
<li>send the model specification and the other data to JAGS, using the function <code>jags.model()</code> from the <code>rjags</code> package; in a few seconds, this function returns samples from the posterior distribution for all the estimated parameters (<code>res3</code>).</li>
</ol>
<p>Once the samples from the posterior have been obtained, we specify that 1000 samples should be discarded as <code>burn.in</code>. These samples might have been produced before reaching the convergence, so they might not come from the correct posterior distribution. In other words, we get rid of them.</p>
<p>From the posterior, we obtain the mean and median as measures of central tendency, the standard deviation as a measure of uncertainty, and credible intervals, which are the Bayesian analog to confidence intervals.</p>
<pre class="r"><code>library(rjags)
win.data &lt;- list(low = dataset_jags$sizeLow, 
                 high = dataset_jags$sizeUp, 
                 N1 = N1, N2 = N2, N = N, 
                 Group = factor(dataset_jags$Group),
                 Photo = factor(dataset_jags$Photo)
                 )

init &lt;- list(mu = c(7.3, 8.7), sigma.e = 1.7, sigma.P = 0.5)
mcmc &lt;- jags.model(&quot;censoredMixedModel.txt&quot;,
                   data = win.data, 
                   inits = init, 
                   n.chains = 4, 
                   n.adapt = 100)</code></pre>
<pre><code>## Compiling data graph
##    Resolving undeclared variables
##    Allocating nodes
##    Initializing
##    Reading data back into data table
## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 2441
##    Unobserved stochastic nodes: 28
##    Total graph size: 13388
## 
## Initializing model
## 
## 
  |                                                        
  |                                                  |   0%
  |                                                        
  |+                                                 |   2%
  |                                                        
  |++                                                |   4%
  |                                                        
  |+++                                               |   6%
  |                                                        
  |++++                                              |   8%
  |                                                        
  |+++++                                             |  10%
  |                                                        
  |++++++                                            |  12%
  |                                                        
  |+++++++                                           |  14%
  |                                                        
  |++++++++                                          |  16%
  |                                                        
  |+++++++++                                         |  18%
  |                                                        
  |++++++++++                                        |  20%
  |                                                        
  |+++++++++++                                       |  22%
  |                                                        
  |++++++++++++                                      |  24%
  |                                                        
  |+++++++++++++                                     |  26%
  |                                                        
  |++++++++++++++                                    |  28%
  |                                                        
  |+++++++++++++++                                   |  30%
  |                                                        
  |++++++++++++++++                                  |  32%
  |                                                        
  |+++++++++++++++++                                 |  34%
  |                                                        
  |++++++++++++++++++                                |  36%
  |                                                        
  |+++++++++++++++++++                               |  38%
  |                                                        
  |++++++++++++++++++++                              |  40%
  |                                                        
  |+++++++++++++++++++++                             |  42%
  |                                                        
  |++++++++++++++++++++++                            |  44%
  |                                                        
  |+++++++++++++++++++++++                           |  46%
  |                                                        
  |++++++++++++++++++++++++                          |  48%
  |                                                        
  |+++++++++++++++++++++++++                         |  50%
  |                                                        
  |++++++++++++++++++++++++++                        |  52%
  |                                                        
  |+++++++++++++++++++++++++++                       |  54%
  |                                                        
  |++++++++++++++++++++++++++++                      |  56%
  |                                                        
  |+++++++++++++++++++++++++++++                     |  58%
  |                                                        
  |++++++++++++++++++++++++++++++                    |  60%
  |                                                        
  |+++++++++++++++++++++++++++++++                   |  62%
  |                                                        
  |++++++++++++++++++++++++++++++++                  |  64%
  |                                                        
  |+++++++++++++++++++++++++++++++++                 |  66%
  |                                                        
  |++++++++++++++++++++++++++++++++++                |  68%
  |                                                        
  |+++++++++++++++++++++++++++++++++++               |  70%
  |                                                        
  |++++++++++++++++++++++++++++++++++++              |  72%
  |                                                        
  |+++++++++++++++++++++++++++++++++++++             |  74%
  |                                                        
  |++++++++++++++++++++++++++++++++++++++            |  76%
  |                                                        
  |+++++++++++++++++++++++++++++++++++++++           |  78%
  |                                                        
  |++++++++++++++++++++++++++++++++++++++++          |  80%
  |                                                        
  |+++++++++++++++++++++++++++++++++++++++++         |  82%
  |                                                        
  |++++++++++++++++++++++++++++++++++++++++++        |  84%
  |                                                        
  |+++++++++++++++++++++++++++++++++++++++++++       |  86%
  |                                                        
  |++++++++++++++++++++++++++++++++++++++++++++      |  88%
  |                                                        
  |+++++++++++++++++++++++++++++++++++++++++++++     |  90%
  |                                                        
  |++++++++++++++++++++++++++++++++++++++++++++++    |  92%
  |                                                        
  |+++++++++++++++++++++++++++++++++++++++++++++++   |  94%
  |                                                        
  |++++++++++++++++++++++++++++++++++++++++++++++++  |  96%
  |                                                        
  |+++++++++++++++++++++++++++++++++++++++++++++++++ |  98%
  |                                                        
  |++++++++++++++++++++++++++++++++++++++++++++++++++| 100%</code></pre>
<pre class="r"><code>params &lt;- c(&quot;mu&quot;, &quot;sigma.e&quot;, &quot;sigma.P&quot;, 
            &quot;sigma2p&quot;, &quot;sigma2e&quot;, &quot;diff&quot;)
res3 &lt;- coda.samples(mcmc, params, n.iter = 10000)</code></pre>
<pre><code>## 
  |                                                        
  |                                                  |   0%
  |                                                        
  |*                                                 |   2%
  |                                                        
  |**                                                |   4%
  |                                                        
  |***                                               |   6%
  |                                                        
  |****                                              |   8%
  |                                                        
  |*****                                             |  10%
  |                                                        
  |******                                            |  12%
  |                                                        
  |*******                                           |  14%
  |                                                        
  |********                                          |  16%
  |                                                        
  |*********                                         |  18%
  |                                                        
  |**********                                        |  20%
  |                                                        
  |***********                                       |  22%
  |                                                        
  |************                                      |  24%
  |                                                        
  |*************                                     |  26%
  |                                                        
  |**************                                    |  28%
  |                                                        
  |***************                                   |  30%
  |                                                        
  |****************                                  |  32%
  |                                                        
  |*****************                                 |  34%
  |                                                        
  |******************                                |  36%
  |                                                        
  |*******************                               |  38%
  |                                                        
  |********************                              |  40%
  |                                                        
  |*********************                             |  42%
  |                                                        
  |**********************                            |  44%
  |                                                        
  |***********************                           |  46%
  |                                                        
  |************************                          |  48%
  |                                                        
  |*************************                         |  50%
  |                                                        
  |**************************                        |  52%
  |                                                        
  |***************************                       |  54%
  |                                                        
  |****************************                      |  56%
  |                                                        
  |*****************************                     |  58%
  |                                                        
  |******************************                    |  60%
  |                                                        
  |*******************************                   |  62%
  |                                                        
  |********************************                  |  64%
  |                                                        
  |*********************************                 |  66%
  |                                                        
  |**********************************                |  68%
  |                                                        
  |***********************************               |  70%
  |                                                        
  |************************************              |  72%
  |                                                        
  |*************************************             |  74%
  |                                                        
  |**************************************            |  76%
  |                                                        
  |***************************************           |  78%
  |                                                        
  |****************************************          |  80%
  |                                                        
  |*****************************************         |  82%
  |                                                        
  |******************************************        |  84%
  |                                                        
  |*******************************************       |  86%
  |                                                        
  |********************************************      |  88%
  |                                                        
  |*********************************************     |  90%
  |                                                        
  |**********************************************    |  92%
  |                                                        
  |***********************************************   |  94%
  |                                                        
  |************************************************  |  96%
  |                                                        
  |************************************************* |  98%
  |                                                        
  |**************************************************| 100%</code></pre>
<pre class="r"><code>burn.in &lt;- 1000</code></pre>
<pre class="r"><code>summary(window(res3, start = burn.in))</code></pre>
<pre><code>## 
## Iterations = 1000:10100
## Thinning interval = 1 
## Number of chains = 4 
## Sample size per chain = 9101 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##            Mean     SD  Naive SE Time-series SE
## diff    -1.4714 0.4392 0.0023019      0.0061106
## mu[1]    7.2296 0.3167 0.0016600      0.0042082
## mu[2]    8.7010 0.3059 0.0016034      0.0044877
## sigma.P  0.7715 0.2538 0.0013301      0.0063199
## sigma.e  6.6046 0.1371 0.0007185      0.0009375
## sigma2e 43.6395 1.8131 0.0095025      0.0124105
## sigma2p  0.6596 0.4173 0.0021873      0.0083689
## 
## 2. Quantiles for each variable:
## 
##             2.5%     25%     50%     75%   97.5%
## diff    -2.35633 -1.7544 -1.4661 -1.1781 -0.6276
## mu[1]    6.58879  7.0257  7.2360  7.4388  7.8399
## mu[2]    8.10428  8.4986  8.6999  8.8998  9.3142
## sigma.P  0.29500  0.6020  0.7638  0.9284  1.3010
## sigma.e  6.34270  6.5114  6.6011  6.6957  6.8798
## sigma2e 40.22986 42.3977 43.5752 44.8320 47.3322
## sigma2p  0.08702  0.3624  0.5833  0.8620  1.6925</code></pre>
<p>We can see that the the expected difference between the producers is equal to -1.477, and that there is a 95% posterior probability that the true difference is between -2.3763 and -0.6164 - so it is different from 0. (Do note, however, that other runs of the model may bring slightly different results). The random effect for the photos has a variance component of 0.66, and its credible interval does not contain 0.</p>
<hr />
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-Plummer:2016aa">
<p><span style="font-variant: small-caps;">Plummer, M</span> (2016) <em>Rjags: Bayesian graphical models using mcmc</em></p>
</div>
<div id="ref-spiegelhalter2003_WinBUGSusermanual">
<p><span style="font-variant: small-caps;">Spiegelhalter, D, A Thomas, N Best, D Lunn</span> (2003) <em>WinBUGS user manual</em>. version</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
